{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pp_mix_cpp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import arviz as az\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from interface import Sampler, to_numpy, writeChains, loadChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7eff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/child_origresp_interactions_missing.pickle\", \"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "    \n",
    "with open(\"data/prior_params_china.pickle\", \"rb\") as fp:\n",
    "    params = pickle.load(fp)\n",
    "\n",
    "    \n",
    "resps = data[\"resps\"]\n",
    "longcovs = data[\"longcovs\"]\n",
    "fixedcovs = data[\"fixedcovs\"]\n",
    "\n",
    "is_missing = data[\"is_missing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d83757",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler(50, \"LinearDDP\")\n",
    "sampler.set_prior(\n",
    "    nu=params[\"nu\"],\n",
    "    sigma0=params[\"sigma0\"],\n",
    "    gamma0=params[\"gamma0\"],\n",
    "    beta0=params[\"beta0\"],\n",
    "    varb=params[\"varb\"],\n",
    "    varg=params[\"varg\"]\n",
    ")\n",
    "\n",
    "chains = sampler.run_mcmc(\n",
    "    0, 100000, 10000, 10, resps, longcovs, fixedcovs, is_missing)\n",
    "\n",
    "writeChains(chains, \"chains/growth_linddp.recordio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains[-1].clus_allocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clus_chain = []\n",
    "for state in chains:\n",
    "    uniq, cnts = np.unique(state.clus_allocs, return_counts=True)\n",
    "    n_clus_chain.append(len(cnts[cnts > 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "uniq, cnts = np.unique(n_clus_chain, return_counts=True)\n",
    "plt.bar(uniq, cnts / np.sum(cnts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7fcd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from scipy.special import logsumexp\n",
    "_LOG_2PI = np.log(2 * np.pi)\n",
    "LOG_EPS = -10000\n",
    "\n",
    "def gen_even_slices(n, n_packs, n_samples=None):\n",
    "    start = 0\n",
    "    if n_packs < 1:\n",
    "        raise ValueError(\"gen_even_slices got n_packs=%s, must be >=1\"\n",
    "                         % n_packs)\n",
    "    for pack_num in range(n_packs):\n",
    "        this_n = n // n_packs\n",
    "        if pack_num < n % n_packs:\n",
    "            this_n += 1\n",
    "        if this_n > 0:\n",
    "            end = start + this_n\n",
    "            if n_samples is not None:\n",
    "                end = min(n_samples, end)\n",
    "            yield slice(start, end, None)\n",
    "            start = end\n",
    "\n",
    "def mvn_lpdf(x, mean, prec_chol, prec_log_det, dim):\n",
    "    dev = x - mean\n",
    "    exp = - 0.5 * np.sum(np.square(np.dot(dev, prec_chol)), axis=-1)\n",
    "    out = -0.5 * dim * _LOG_2PI + 0.5 * prec_log_det + exp\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_joint_prec(tmax, Phi, Sigma):\n",
    "    dim = Sigma.shape[0] \n",
    "    prec = np.zeros((tmax * dim, tmax * dim)) \n",
    "    I = np.eye(dim)\n",
    "    sigma_inv = np.linalg.inv(Sigma)\n",
    "#     diag_block = np.matmul((I + Phi).T, np.matmul(sigma_inv, I + Phi))  \n",
    "#     offdiag_block = np.matmul(Phi.T, sigma_inv)\n",
    "    \n",
    "    diag_block = np.matmul((I + Phi).T, np.linalg.solve(Sigma, I + Phi))  \n",
    "    offdiag_block = np.linalg.solve(Sigma.T, Phi).T\n",
    "    for i in range(tmax-1):\n",
    "        prec[i*dim:(i+1)*dim, i*dim:(i+1)*dim] = diag_block\n",
    "        prec[i*dim:(i+1)*dim, (i+1)*dim:(i+2)*dim] = offdiag_block\n",
    "        prec[(i+1)*dim:(i+2)*dim, i*dim:(i+1)*dim] = offdiag_block.T\n",
    "\n",
    "    prec[(tmax-1)*dim:, (tmax-1)*dim:] = sigma_inv\n",
    "    return 0.5 * (prec + prec.T)\n",
    "\n",
    "def eval_joint_lpdf(B, Gamma, Regressor, Sigma, y, x, z):\n",
    "    tmax = y.shape[0]\n",
    "    mean = ((B * x[:tmax, 0]).T + np.matmul(Gamma, z)).ravel()\n",
    "    phivec = np.matmul(Regressor, z)\n",
    "    Phi = phivec.reshape(2, 2)\n",
    "    prec = get_joint_prec(y.shape[0], Phi, Sigma)\n",
    "    y = y.ravel()\n",
    "    keep = np.where(y >= 0)[0]\n",
    "    y = y[keep]\n",
    "    mean = mean[keep]\n",
    "    prec = prec[keep, :][:, keep]\n",
    "    try:\n",
    "        prec_chol = np.linalg.cholesky(prec)\n",
    "        prec_logdet = 2 * np.sum(np.log(np.diag(prec_chol)))\n",
    "        return mvn_lpdf(y, mean, prec_chol, prec_logdet, y.shape[0])\n",
    "    except:\n",
    "        return LOG_EPS\n",
    "\n",
    "\n",
    "def eval_multiple_lpdf(Bchain, Gchain, Regchain_vec, SigmaChain, y, x, z):\n",
    "    out = np.zeros((Bchain.shape[0], Regchain_vec.shape[1]))\n",
    "    for i in range(Bchain.shape[0]):\n",
    "        for j in range(Regchain_vec.shape[1]):\n",
    "            regmat = Regchain_vec[i, j, :].reshape(4, 16)\n",
    "            out[i, j] = eval_joint_lpdf(\n",
    "                Bchain[i], Gchain[i], regmat, SigmaChain[i],\n",
    "                y, x, z)\n",
    "            \n",
    "    return out\n",
    "\n",
    "def eval_mixture_dens(chains, resps, longcovs, fixedcovs):\n",
    "    betachain = np.stack([to_numpy(x.beta) for x in chains])\n",
    "    gammachain = np.stack([to_numpy(x.gamma) for x in chains])\n",
    "    sigmachain = np.stack([to_numpy(x.sigma) for x in chains])\n",
    "\n",
    "    regchain = np.zeros(\n",
    "        (len(chains), len(chains[0].lindpp_regressors), \n",
    "         chains[0].lindpp_regressors[0].size))\n",
    "    for i in range(len(chains)):\n",
    "        regchain[i, :, :] = np.stack([to_numpy(x) for x in chains[i].lindpp_regressors])\n",
    "\n",
    "    fd = delayed(eval_multiple_lpdf)\n",
    "    eval_normals = np.zeros((len(resps), len(chains), len(chains[0].lindpp_regressors)))\n",
    "    for i in range(len(resps)):\n",
    "        print(\"\\r {0}/{1}\".format(i+1, len(resps)), flush=True, end=\" \")\n",
    "        curr_dens = Parallel(n_jobs=6)(\n",
    "            fd(betachain[s, :, :], gammachain[s, :, :], regchain[s, :, :],\n",
    "              sigmachain[s, :, :], resps[i], longcovs[i], fixedcovs[i])\n",
    "            for s in gen_even_slices(len(chains), 6))\n",
    "        eval_normals[i, :, :] = np.vstack(curr_dens)\n",
    "        #eval_normals[i, :, :] = eval_multiple_lpdf(\n",
    "        #    betachain, gammachain, regchain,\n",
    "        #    sigmachain, resps[i], longcovs[i], fixedcovs[i]\n",
    "        #)\n",
    "\n",
    "    return eval_normals\n",
    "    \n",
    "def eval_ldpp_dens(chains, resps, longcovs, fixedcovs):\n",
    "    weightschain = np.vstack([to_numpy(x.dp_weights) for x in chains])\n",
    "    eval_normals = eval_mixture_dens(chains, resps, longcovs, fixedcovs)\n",
    "    out = logsumexp(eval_normals + np.log(weightschain), axis=-1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def lpml(log_densities):\n",
    "    inv_cpos = np.mean(1.0 / np.exp(log_densities), axis=0)\n",
    "    return np.sum(-np.log(inv_cpos))\n",
    "\n",
    "\n",
    "def waic(log_densities):\n",
    "    # log densities: nsamples x ndata\n",
    "    print(log_densities.shape)\n",
    "    log_pred_dens = logsumexp(log_densities, axis=0) - np.log(log_densities.shape[0])\n",
    "    # log_pred_dens: ndata\n",
    "    print(log_pred_dens.shape)\n",
    "    lpd = np.sum(log_pred_dens)\n",
    "    p_waic = np.sum(np.var(log_pred_dens), axis=0)\n",
    "    return lpd - p_waic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a91eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldpp_densities = eval_ldpp_dens(chains, resps, longcovs, fixedcovs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains[0].lindpp_regressors[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30db6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpml(ldpp_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "waic(ldpp_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(1e-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsb_chains = loadChains(\"data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
